{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<a href=\"http://www.insa-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo-insa.jpg\" style=\"float:left; max-width: 120px; display: inline\" alt=\"INSA\"/></a> \n",
    "\n",
    "<a href=\"http://wikistat.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/wikistat.jpg\" style=\"max-width: 250px; display: inline\"  alt=\"Wikistat\"/></a>\n",
    "\n",
    "<a href=\"http://www.math.univ-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo_imt.jpg\" style=\"float:right; max-width: 200px; display: inline\" alt=\"IMT\"/> </a>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Scénarios d'Exploration Statistique](https://github.com/wikistat/Exploration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse de signaux  issus d'un *smartphone* en <a href=\"https://www.python.org/\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/f/f8/Python_logo_and_wordmark.svg/390px-Python_logo_and_wordmark.svg.png\" style=\"max-width: 120px; display: inline\" alt=\"Python\"/></a> avec <a href=\"http://scikit-learn.org/stable/#\"><img src=\"http://scikit-learn.org/stable/_static/scikit-learn-logo-small.png\" style=\"max-width: 100px; display: inline\" alt=\"Scikit-Learn\"/></a>\n",
    "##  Signaux bruts: visualisation des données et [ACP ](http://wikistat.fr/pdf/st-m-explo-acp.pdf)\n",
    "\n",
    "### Résumé\n",
    "Ce cas d'usage de [reconnaissance d'activités humaines](https://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones) à partir des enregistrements d'un smartphone (gyroscope, accéléromètre) est traité pour illustrer les principales étapes d'exploration  communes en *science des données* et appliquables à des signaux échantillonnés. Ce calepin propose de visualiser ces signaux puis de réaliser des ACP afin d'identifier les problèmes spécifiques soulevés par ce type de données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1 Introduction\n",
    "### 1.1  Contexte\n",
    "Les données sont issues de la communauté qui vise la reconnaissance d'activités humaines (*Human activity recognition, HAR*) à partir d’enregistrements, par exemple du gyroscope et de l'accéléromètre d'un smartphone alors que le porteur produit une activité déterminée a priori pendnat un laps de temps défini.\n",
    "\n",
    "Voir à ce propos l'[article](https://www.elen.ucl.ac.be/Proceedings/esann/esannpdf/es2013-11.pdf) relatant un colloque de 2013.  \n",
    "\n",
    "Les données publiques disponibles et largement étudiées ont été acquises, décrites et analysées par [Anguita et al. (2013)](). Elles sont accessibles sur le [dépôt](https://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones) de l'University California Irvine (UCI) consacré à l'apprentissage machine ainsi que sur le site *Kaggle*.\n",
    "\n",
    "L'archive contient les données brutes: accélérations échantillonnnées à 64 htz pendant 2s. Les accélérations en x, y, et z, chacune de 128 colonnes, celles en y soustrayant la gravité naturelle ainsi que les accélérations angulaires (gyroscope) en x, y, et z soit en tout 9 fichiers.\n",
    "\n",
    "Ce sont ces données brutes qui sont analysées tandis qu'un [autre calepin]() étudie des transformations expertes ou métier de celles-ci sous la forme de nouvelles variables ou *features*. \n",
    "\n",
    "### 1.2 Objectifs\n",
    "L'[analyse des nouvelles variables]() issues de transformations des signaux (entropie, variance, corrélations, Fourier...) conduit à d'excellents résultats au moment de la reconnaisance de l'activité. Néanmoins, il est nécessaire de  s'intéresser directement aux données brutes avec pour objectif d'économiser les calculs lourds et énergivores pour un système embarqué ou porté par un individu. Un [autre calepin] aborde cette question: obtenir la même qualité de reconnaissance que sur les variables transformées mais par un réseau de neurones (*deep learning*) qui, une fois implémenté, sera de faible consommation comme peuvent l'être les circuits de reconnaissance des visages sur un appareil photo.\n",
    "\n",
    "Comme pour les données métier, l'étude commence par une exploration: visualisation des données, réduction de dimension par ACP.\n",
    "\n",
    "### 1.3 Librairies\n",
    "Importation des principales librairies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import random\n",
    "import itertools\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.decomposition as sdec "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Prise en charge des données\n",
    "### 2.1 Source\n",
    "\n",
    "Les données sont celles originales du dépôt de l'[UCI](https://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones). Elle doivent être préalablement téléchargées en cliquant [ici](https://archive.ics.uci.edu/ml/machine-learning-databases/00240/UCI%20HAR%20Dataset.zip).\n",
    "\n",
    "Elles contiennent deux jeux de dimensions différentes, chacun partagé en apprentissage et test. L'échantillon test n'est utilisé que pour dans les calepins d'apprentisage. \n",
    "\n",
    "1. Multidimensionel: un individus est constitué de 9 Séries Temporelles de *dimensions* $(N, 128, 9)$\n",
    "2. Unidimensionnel: Les 9 Séries Temporelles sont concaténées pour constituer un vecteur de 128*9 = 1152 variables de *dimensions* $(N, 1152)*\n",
    "\n",
    "*N.B.* La structure des données est nettement plus complexe que celles couramment étudiées dans ce dépôt. Le code a été structuré en une séquence de fonctions afin d'en faciliter la compréhension. L'outil \"calepin\" atteint ici des limites pour la réalisation de codes complexes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Structurer les données\n",
    "Définir le chemin d'accès aux données puis les fonctions utiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention à la définition du chemin ci-dessous:\n",
    "DATADIR_UCI = '/home-local/pbesse/Documents/2-Data_files/HAR/UCI HAR Dataset'\n",
    "# Liste des fichiers afin d'automatiser la lecture.\n",
    "SIGNALS = [ \"body_acc_x\", \"body_acc_y\", \"body_acc_z\", \"body_gyro_x\", \"body_gyro_y\", \"body_gyro_z\", \"total_acc_x\", \"total_acc_y\", \"total_acc_z\"]\n",
    "\n",
    "# Fonctions permettant de lire la séquence des fichiers avant de restructurer les données \n",
    "# dans le fortmat recherché.\n",
    "def my_read_csv(filename):\n",
    "    return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
    "\n",
    "def load_signal(data_dir, subset, signal):\n",
    "    filename = data_dir+'/'+subset+'/Inertial Signals/'+signal+'_'+subset+'.txt'\n",
    "    x = my_read_csv(filename).as_matrix()\n",
    "    return x \n",
    "\n",
    "def load_signals(data_dir, subset, flatten = False):\n",
    "    signals_data = []\n",
    "    for signal in SIGNALS:\n",
    "        signals_data.append(load_signal(data_dir, subset, signal)) \n",
    "    if flatten :\n",
    "        X = np.hstack(signals_data)\n",
    "    else:\n",
    "        X = np.transpose(signals_data, (1, 2, 0))    \n",
    "    return X \n",
    "\n",
    "def load_y(data_dir, subset, dummies = False):\n",
    "    filename = data_dir+'/'+subset+'/y_'+subset+'.txt'\n",
    "    y = my_read_csv(filename)[0]\n",
    "    if dummies:\n",
    "        Y = pd.get_dummies(y).as_matrix()\n",
    "    else:\n",
    "        Y = y.as_matrix()\n",
    "    return Y "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lecture des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multidimensional Data\n",
    "X_train, X_test = load_signals(DATADIR_UCI, 'train'), load_signals(DATADIR_UCI, 'test')\n",
    "# Flattened Data\n",
    "X_train_flatten, X_test_flatten = load_signals(DATADIR_UCI, 'train', flatten=True), load_signals(DATADIR_UCI, 'test', flatten=True)\n",
    "\n",
    "# Label Y\n",
    "Y_train_label, Y_test_label = load_y(DATADIR_UCI, 'train', dummies = False), load_y(DATADIR_UCI, 'test', dummies = False)\n",
    "#Dummies Y (For Keras)\n",
    "Y_train_dummies, Y_test_dummies = load_y(DATADIR_UCI, 'train', dummies = True), load_y(DATADIR_UCI, 'test', dummies = True)\n",
    "\n",
    "N_train = X_train.shape[0]\n",
    "N_test = X_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vérification des dimensions afin de s'assurer de la bonne lecture des fichiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dimension\")\n",
    "print(\"Données Multidimensionelles, : \" + str(X_train.shape))\n",
    "print(\"Données Unimensionelles, : \" + str(X_train_flatten.shape))\n",
    "print(\"Vecteur réponse (scikit-learn) : \" + str(Y_train_label.shape))\n",
    "print(\"Matrice réponse(Keras) : \" + str(Y_train_dummies.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Visualisations\n",
    "Certre phase est essentielle à la bonne compréhension des données, de leur structure et don cdes problèmes qui vont être soulevés par la suite. La visualisation est très élémentaire d'un point de vue méthodologique mais nécessite des compétences avancées dans \n",
    "### 3.1 Fonctions utiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste des couleurs\n",
    "CMAP = plt.get_cmap(\"Accent\")\n",
    "# Liste des types de signaux\n",
    "SIGNALS = [\"body_acc x\", \"body_acc y\", \"body_acc z\", \n",
    "                \"body_gyro x\", \"body_gyro y\", \"body_gyro z\", \n",
    "               \"total_acc x\", \"total_acc y\", \"total_acc z\"] \n",
    "# Dictionnaire en clair des activités expérimentées (contexte supervisé)\n",
    "ACTIVITY_DIC = {1 : \"WALKING\",\n",
    "2 : \"WALKING UPSTAIRS\",\n",
    "3 : \"WALKING DOWNSTAIRS\",\n",
    "4 : \"SITTING\",\n",
    "5 : \"STANDING\",\n",
    "6 : \"LAYING\"}\n",
    "\n",
    "# Fonction pour le tracé d'un signal\n",
    "def plot_one_axe(X, fig, ax, sample_to_plot, cmap):\n",
    "    for act,Xgb in X.groupby(\"Activity\"):\n",
    "        Xgb_first_values = Xgb.values[:sample_to_plot,:-1]\n",
    "        x = Xgb_first_values[0]\n",
    "        ax.plot(x, linewidth=1, color=cmap(act-1), label = label_dic[act])\n",
    "        for x in Xgb_first_values[1:]:\n",
    "            ax.plot(x, linewidth=1, color=cmap(act-1))\n",
    "\n",
    "            \n",
    "def plot_one_axe_shuffle(X, fig, ax, sample_to_plot, cmap):\n",
    "    plot_data = []\n",
    "    for act,Xgb in X.groupby(\"Activity\"):\n",
    "        Xgb_first_values = Xgb.values[:sample_to_plot,:-1]\n",
    "        x = Xgb_first_values[0]\n",
    "        ax.plot(x, linewidth=1, color=cmap(act-1), label = label_dic[act])\n",
    "        for x in Xgb_first_values[1:]:\n",
    "            plot_data.append([x,cmap(act-1)])\n",
    "    random.shuffle(plot_data)\n",
    "    for x,color in plot_data:\n",
    "        ax.plot(x, linewidth=1, color=color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 3.2 Tracés de tous les signaux\n",
    "Tous le signaux sont tracés par type en superposant les activités."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_to_plot = 50\n",
    "index_per_act = [list(zip(np.repeat(act, sample_to_plot), np.where(Y_train_label==act)[0][:sample_to_plot])) for act in range(1,7)]\n",
    "index_to_plot = list(itertools.chain.from_iterable(index_per_act))\n",
    "random.shuffle(index_to_plot)\n",
    "\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "for isignal in range(9):\n",
    "    ax = fig.add_subplot(3,3,isignal+1)\n",
    "    for act , i in index_to_plot:\n",
    "        ax.plot(range(128), X_train[i,:,isignal],color=CMAP(act-1), linewidth=1)\n",
    "        ax.set_title(SIGNALS[isignal])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Apprécier la difficulté à distinguer les activités.\n",
    "\n",
    "### 3.3 Par signal \n",
    "Un seul signal acélération en x est tracé en distinguant les activités."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_to_plot = 10\n",
    "isignal = 1\n",
    "index_per_act_dict = dict([(act, np.where(Y_train_label==act)[0][:sample_to_plot]) for act in range(1,7)])\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(15,8), num=SIGNALS[isignal])\n",
    "for act , index in index_per_act_dict.items():\n",
    "    ax = fig.add_subplot(3,2,act)\n",
    "    for x in X_train[index]:\n",
    "        ax.plot(range(128), x[:,0],color=CMAP(act-1), linewidth=1)\n",
    "    ax.set_title(ACTIVITY_DIC[act])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Quelles est l'activité qui semble se distinguer facilement des autres? \n",
    "\n",
    "**Q** Observer l'un des signaux, par exemple `Walking upstairs`. Qu'est ce qui fait que, pour ces signaux ou courbes, une métrique euclidienne classique ($L_2$) est inopérante? \n",
    "\n",
    "**Q** Corrélativement pourquoi est-il intéressant de décomposer un signal dans le domaine des fréquences?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 [Analyse en composantes principales](http://wikistat.fr/pdf/st-m-explo-acp.pdf)\n",
    "Les ACP ne sont pas réduites car cette transformation n'a finalement pas d'effet sensible sur la discrimination des classes.\n",
    "\n",
    "Fonction graphique pour la représentation d'un plan factoriel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pca(X_R, ytrain, fig, ax, nbc, nbc2, label_dic=ACTIVITY_DIC, cmaps = plt.get_cmap(\"Accent\")\n",
    "):\n",
    "    for i in range(6):\n",
    "        xs = X_R[ytrain==i+1,nbc-1]\n",
    "        ys = X_R[ytrain==i+1, nbc2-1]\n",
    "        label = label_dic[i+1]\n",
    "        color = cmaps(i)\n",
    "        ax.scatter(xs, ys, color=color, alpha=.8, s=10, label=label)\n",
    "        ax.set_xlabel(\"PC%d : %.2f %%\" %(nbc,pca.explained_variance_ratio_[nbc-1]*100), fontsize=15)\n",
    "        ax.set_ylabel(\"PC%d : %.2f %%\" %(nbc2,pca.explained_variance_ratio_[nbc2-1]*100), fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Sur un Signal\n",
    "Calcul de l'ACP sur un seul signal: accélération angulaire (gyroscope) en y. Il suffit de changer la valeur ci-dessous de `isignal` pour en étudier d'autres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = sdec.PCA()\n",
    "# CHoix du signal\n",
    "isignal = 4\n",
    "signal = SIGNALS[isignal]\n",
    "print(\"ACP Sur signal : \" +signal)\n",
    "X_r = pca.fit_transform(X_train[:,:,isignal])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Représentation des parts de variances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,10))\n",
    "ax = fig.add_subplot(1,2,1)\n",
    "ax.bar(range(10), pca.explained_variance_ratio_[:10]*100, align='center',\n",
    "        color='grey', ecolor='black')\n",
    "ax.set_xticks(range(10))\n",
    "ax.set_ylabel(\"Variance\")\n",
    "ax.set_title(\"\", fontsize=35)\n",
    "ax.set_title(u\"Pourcentage de variance expliquée \\n par les premières composantes\", fontsize=20)\n",
    "\n",
    "ax = fig.add_subplot(1,2,2)\n",
    "box=ax.boxplot(X_r[:,0:10],whis=100)\n",
    "ax.set_title(u\"Distribution des premières composantes\", fontsize=20)\n",
    "\n",
    "fig.suptitle(u\"Résultat ACP sur Signal : \" + signal, fontsize=25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Attention**: les diagrammes boîtes sont très perturbés pas les distributions des composantes avec une très forte concentration autour de 0 et énormément de valeurs atypiques. D'où l'utilisation du paramètre `whis=100` pour rallonger les moustaches.\n",
    "\n",
    "**Q** Que osnt les graphes ci-dessus. Quelles interprétations ou absence d'interprétation en tirer?\n",
    "\n",
    "Représentation du premier plan factoriel;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10), )\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "plot_pca(X_r, Y_train_label,fig ,ax ,1 ,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10), )\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "plot_pca(X_r, Y_train_label,fig ,ax ,1 ,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faire varier `isignal` pour comparer.\n",
    "\n",
    "**Q** la discrimination des classes semble-elle facile à partir des signaux bruts?\n",
    "\n",
    "### 4.2 Sur tous les signaux\n",
    "Tous les signaux sont concaténés à plat en un seul signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = sdec.PCA()\n",
    "print(\"ACP Sur tous les signaux\")\n",
    "X_r = pca.fit_transform(X_train_flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,10))\n",
    "ax = fig.add_subplot(1,2,1)\n",
    "ax.bar(range(10), pca.explained_variance_ratio_[:10]*100, align='center',\n",
    "        color='grey', ecolor='black')\n",
    "ax.set_xticks(range(10))\n",
    "ax.set_ylabel(\"Variance\")\n",
    "ax.set_title(\"\", fontsize=35)\n",
    "ax.set_title(u\"Pourcentage de variance expliqué \\n des premières composantes\", fontsize=20)\n",
    "\n",
    "ax = fig.add_subplot(1,2,2)\n",
    "box=ax.boxplot(X_r[:,0:10],whis=100)\n",
    "ax.set_title(u\"Distribution des premières composantes\", fontsize=20)\n",
    "\n",
    "fig.suptitle(u\"Résultat ACP\", fontsize=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10), )\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "plot_pca(X_r, Y_train_label,fig ,ax ,1 ,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Quelle est l'activité qui semble plus facile à identifier?"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
