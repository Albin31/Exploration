{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<a href=\"http://www.insa-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo-insa.jpg\" style=\"float:left; max-width: 120px; display: inline\" alt=\"INSA\"/></a> \n",
    "\n",
    "<a href=\"http://wikistat.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/wikistat.jpg\" style=\"max-width: 250px; display: inline\"  alt=\"Wikistat\"/></a>\n",
    "\n",
    "<a href=\"http://www.math.univ-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo_imt.jpg\" style=\"float:right; max-width: 200px; display: inline\" alt=\"IMT\"/> </a>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Scénarios d'Exploration Statistique](https://github.com/wikistat/Exploration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse de signaux  issus d'un *smartphone* en <a href=\"https://www.python.org/\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/f/f8/Python_logo_and_wordmark.svg/390px-Python_logo_and_wordmark.svg.png\" style=\"max-width: 120px; display: inline\" alt=\"Python\"/></a> avec <a href=\"http://scikit-learn.org/stable/#\"><img src=\"http://scikit-learn.org/stable/_static/scikit-learn-logo-small.png\" style=\"max-width: 100px; display: inline\" alt=\"Scikit-Learn\"/></a>\n",
    "## Données transformées (métier): exploration et première modélisation par [ACP](http://wikistat.fr/pdf/st-m-explo-acp.pdf), [AFD](http://wikistat.fr/pdf/st-m-explo-afd.pdf), [régression logistique](http://wikistat.fr/pdf/st-m-app-rlogit.pdf).\n",
    "\n",
    "### Résumé\n",
    "Ce cas d'usage de [reconnaissance d'activités humaines](https://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones) à partir des enregistrements d'un smartphone (gyroscope, accéléromètre) est traité pour illustrer les principales étapes d'exploration et apprentissage communes en *science des données* et appliquables à des signaux. Les données analysées sont obtenues après transformation \"métier\" des données brutes afin de caractériser au mieux les comportements. Exploration multidimensionnelle par méthodes factorielles, classification non supervisée, avant d'introduire le problème de classification supervisée pour prévoir l'activité. La régression logistique est testée avec succès."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Introduction\n",
    "### 1.1 Contexte\n",
    "Les données sont issues de la communauté qui vise la reconnaissance d'activités humaines (*Human activity recognition, HAR*) à partir d’enregistrements, par exemple du gyroscope et de l'accéléromètre d'un smartphone. Voir à ce propos l'[article](https://www.elen.ucl.ac.be/Proceedings/esann/esannpdf/es2013-11.pdf) relatant un colloque de 2013.  \n",
    "\n",
    "Les données publiques disponibles et largement étudiées ont été acquises, décrites et analysées par [Anguita et al. (2013)](). Elles sont accessibles sur le [dépôt](https://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones) de l'University California Irvine (UCI) consacré à l'apprentissage machine ainsi que sur le site *Kaggle*.\n",
    "\n",
    "L'archive contient les données brutes: accélérations échantillonnnées à 64 htz pendant 2s. Les accélérations en x, y, et z, chacune de 128 colonnes, celles en y soustrayant la gravité naturelle ainsi que les accélérations angulaires (gyroscope) en x, y, et z soit en tout 9 fichiers.\n",
    "\n",
    "Il sagit donc d'un ensemble de signaux comme il est extrêmement fréquent d'en rencontrer en lien avec des objets connectés, ici un smartphone, ou dans tout environnement industriel ou scientifique. Les approches développées dans les calepins traitant de ces données sont tout à fait génériques.\n",
    "\n",
    "L'**archive contient également** deux fichiers `train` et `test` de 561 *features* ou variables \"métier\" calculées dans les domaines temporels et fréquentiels à partir des signaux bruts.\n",
    "\n",
    "Les données, chaque enregistrement échantilloné 128 fois, sont labellisées avec **6 activités**: debout, assis, couché, marche, monter ou descendre un escalier. Il s'agit donc d'un problème de classification supervisée (6 classes) avec 10299 échantillons pour l'apprentissage, 2947 pour le test, décrites par 561 variables métiers ou 768 mesures issues de l'échantillonnage des signaux.\n",
    "\n",
    "Voici une liste indicative des variables calculées sur chacune des variables initiales et couples de variables:\n",
    "\n",
    "Name|Signification\n",
    "-|-\n",
    "mean | Mean value\n",
    "std | Standard deviation\n",
    "mad | Median absolute value\n",
    "max | Largest values in array\n",
    "min | Smallest value in array\n",
    "sma | Signal magnitude area\n",
    "energy | Average sum of the squares\n",
    "iqr | Interquartile range\n",
    "entropy | Signal Entropy\n",
    "arCoeff | Autorregresion coefficients\n",
    "correlation | Correlation coefficient\n",
    "maxFreqInd | Largest frequency component\n",
    "meanFreq | Frequency signal weighted average\n",
    "skewness | Frequency signal Skewness\n",
    "kurtosis | Frequency signal Kurtosis\n",
    "energyBand | Energy of a frequency interval\n",
    "angle | Angle between two vectors\n",
    "\n",
    "### 1.2 Objectifs\n",
    "Ce calepin s'intéresse aux seules variables construites à partir des connaissances *a priori* du comportement des capteurs en fonction des types d'activité humaine. IL propose une exploration et une modélisation, des 561 variables métier. Il s'agit de répondre à la question: est-il possible d'identifier l'activité du porteur du smartphone à partir d'un enregistrement? \n",
    "\n",
    "\n",
    "Un [autre calepin]()  s'intéresse aux données brutes afin d'économiser le travail préliminaire de définition des variables métier en utilisant, par exemple, des décompositions systématiques sur une base d'ondelettes ou mieux un algorihtme d'apprentissage profond sur les seules données brutes. L'enjeu est d'obtenir une discrimination sur les données brutes donc moins énergivores qu'un calcul systématique des caractéristiques métier.\n",
    "\n",
    "Une *troisième étape* viserait à traiter les données à flux continu pour une application réelle de la reconnaissance d'activité afin, par exemple, de sécuriser des personnes dépendantes ou d'évaluer l'activité physique d'un assuré...\n",
    "\n",
    "Une optimisation poussée de la modélisation des méthodes d'apprentissage sur les données métiers comme le traitement direct des données bruts sont abordés dans d'autres calepins. L'objectif est d'abord une sensibilisation au traitement de données complexes temporelles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des principals librairies et \n",
    "# Affichage des graphiques dans le notebook\n",
    "%matplotlib inline \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Lecture des données métier\n",
    "\n",
    "Les données peuvent être préalablement téléchargées ou directement lues. Ce sont celles originales du dépôt de l'[UCI](https://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lecture des données d'apprentissage\n",
    "# Attention, il peut y avoir plusieurs espaces comme séparateur dans le fichier\n",
    "Xtrain=pd.read_table(\"X_train.txt\",sep='\\s+',header=None)\n",
    "Xtrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable cible\n",
    "ytrain=pd.read_table(\"y_train.txt\",sep='\\s+',header=None,names=('y'))\n",
    "# Le type dataFrame est inutile et même gênant pour les la suite\n",
    "ytrain=ytrain[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lecture des données de test\n",
    "Xtest=pd.read_table(\"X_test.txt\",sep='\\s+',header=None)\n",
    "Xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest=pd.read_table(\"y_test.txt\",sep='\\s+',header=None,names=('y'))\n",
    "ytest=ytest[\"y\"]\n",
    "# Significaiton des codes de y\n",
    "label_dic = {1 : \"Marcher\",2 : \"Monter escalier\",3 : \"Descendre escalier\",\n",
    "   4 : \"Assis\",5 : \"Debout\",6 : \"Couche\"}\n",
    "labels = label_dic.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Exploration par [Analyse en composantes principales](http://wikistat.fr/pdf/st-m-explo-acp.pdf)\n",
    "### 2.1 Principe\n",
    "Il est important de se faire une idée précise de la structure des données.  Une analyse en composantes principales est adaptée à cet objectif. \n",
    "\n",
    "   - Elle recherche les axes de plus grande dispersion du nuages des individus dans $R^p$ avec $p=561$. Ces axes sont définis par les vecteurs propres de la matrice des covariances ou des corrélations si les variables sont réduites (divisées par l'écart-type).\n",
    "   - Les représentations graphiques des individus sont obtenues par projection sur les sous-espaces engendrés par les premiers vecteurs propres. Elles préservent au mieux les distances entre ceux-ci.\n",
    "   - Les coordonnées sont stockées dans la matrice des *composantes principales* qui sont aussi les combinaisons linéaires de plus grande variance des variables. Ce sont des variables décorrélées, orthogonales deux à deux.\n",
    "   - Les representations graphiques des variables initiales conservent au mieux les angles entre les vecteurs variables dans l'espace $R^n$ de façon à interpréter leurs corrélations qui, géométriquement, sont les cosinus de ces angles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction définie ci-après affiche un nuage de points dans un plan factoriel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pca(X_R,fig,ax,nbc,nbc2):\n",
    "    for i in range(6):\n",
    "        xs = X_R[ytrain==i+1,nbc-1]\n",
    "        ys = X_R[ytrain==i+1, nbc2-1]\n",
    "        label = label_dic[i+1]\n",
    "        color = cmaps(i)\n",
    "        ax.scatter(xs, ys, color=color, alpha=.8, s=1, label=label)\n",
    "        ax.set_xlabel(\"PC%d : %.2f %%\" %(nbc,pca.explained_variance_ratio_[nbc-1]*100), fontsize=10)\n",
    "        ax.set_ylabel(\"PC%d : %.2f %%\" %(nbc2,pca.explained_variance_ratio_[nbc2-1]*100), fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcul de la matrice des composantes principales. C'est aussi un changement (transformation) de base; de la base canonique dans la base des vecteurs propres. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "X_r = pca.fit_transform(Xtrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Valeurs propres ou variances des composantes principales\n",
    "Représentation de la décroissance des valeurs propres, les variances des variables ou composantes principales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pca.explained_variance_ratio_[0:10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un graphique plus explicite décrit les distribution de ces composantes par des diagrames boîtes; seules les premières sont affichées. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(X_r[:,0:10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commenter la décroissance des variances, le choix éventuel d'une dimension ou nombre de composantes à retenir sur les 561.\n",
    "### 2.3 Représentation des individus ou \"activités\"\n",
    "Projection dans les principaux plans factoriels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmaps = plt.get_cmap(\"Accent\")\n",
    "fig = plt.figure(figsize= (20,20))\n",
    "count = 0\n",
    "for nbc, nbc2,count in [(1,2,1), (2,3,2), (3,4,3), (1,3,4), (2,4,5), (1,4,7)] :\n",
    "    ax = fig.add_subplot(3,3,count)\n",
    "    plot_pca(X_r, fig,ax,nbc,nbc2)\n",
    "plt.legend(loc='upper right', bbox_to_anchor=(1.8, 0.5), markerscale=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Commenter la séparation des deux types de situation par le premier axe.\n",
    "\n",
    "**Q** Que dire sur la forme des nuages?\n",
    "\n",
    "**Q** Que dire sur la plus ou moins bonne séparation des classes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 2.4 Représentation des variables\n",
    "Lecture des libellés des variables et constitution d'une liste. Souci de la grande dimension (561), les représentations ne sont guère exploitables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('features.txt', 'r') as content_file:\n",
    "    featuresNames = content_file.read()\n",
    "columnsNames = list(map(lambda x : x.split(\" \")[1],featuresNames.split(\"\\n\")[:-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graphe illisible en mettant les libellés en clair. Seule une * est représentée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coordonnées des variables\n",
    "coord1=pca.components_[0]*np.sqrt(pca.explained_variance_[0])\n",
    "coord2=pca.components_[1]*np.sqrt(pca.explained_variance_[1])\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "for i, j in zip(coord1,coord2, ):\n",
    "    plt.text(i, j, \"*\")\n",
    "    plt.arrow(0,0,i,j,color='r')\n",
    "plt.axis((-1.2,1.2,-1.2,1.2))\n",
    "# cercle\n",
    "c=plt.Circle((0,0), radius=1, color='b', fill=False)\n",
    "ax.add_patch(c)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identificaiton des variables participant le plus au premier axe. Ce n'est pas plus clair! Seule la réprésentation des individus apporte finalement des éléments de compréhension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(columnsNames)[abs(coord1)>.6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Exploration par [Analyse Factorielle Discriminante (AFD)](http://wikistat.fr/pdf/st-m-explo-afd.pdf)\n",
    "### 3.1 Principe\n",
    "L'ACP ne prend pas en compte la présence de la variable qualitative à modéliser contrairement à l'analyse factorielle discriminante (AFD) adaptés à ce contexte \"supervisé\" puisque l'activité est connue sur un échantillon d'apprentissage. L'AFD est une ACP des barycentres des classes munissant l'espace des indivudus d'une métrique spécifique dite de *Mahalanobis*. Métrique définie par l'inverse de la matrice de covariance intraclase. L'objectif est alors de visualiser les capacités des variables à discriminer les classes.\n",
    "\n",
    "La librairie `scikit-learn` ne propose pas de fonction spécifique d'analyse factorielle discriminante mais les coordonnées des individus dans la base des vecteurs discriminants sont obtenues comme résultats de l'analyse discriminante linéaire décisionnnelle. Cette dernière sera utilisé avec une finalité prédictive dans un deuxième temps (autre calepin). \n",
    "\n",
    "Les résultats de la fonction `LinearDiscriminantAnalysis` de `scikit-learn` sont identiques à ceux de la fonction `lda` de R. Elle eest donc utilisée strictement de la même façon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "method = LinearDiscriminantAnalysis() \n",
    "lda=method.fit(Xtrain,ytrain)\n",
    "X_r2=lda.transform(Xtrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Que signifie le *warning*? Quel traitement faudrait-t-il mettre en oeuvre dans la partie \"modélisation\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Représentation des individus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize= (20,20))\n",
    "count = 0\n",
    "for nbc, nbc2,count in [(1,2,1), (2,3,2), (3,4,3), (1,3,4), (2,4,5), (1,4,7)] :\n",
    "    ax = fig.add_subplot(3,3,count)\n",
    "    plot_pca(X_r2, fig,ax,nbc,nbc2)\n",
    "plt.legend(loc='upper right', bbox_to_anchor=(1.8, 0.5), markerscale=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Que dire de la séparation des classes. Sont-elles toutes séparables deux à deux?\n",
    "\n",
    "**Q** Que dire de la forme des nuages notamment dans le premier plan?\n",
    "\n",
    "Comme pour l'ACP, la représentation des variables n'apporterait rien."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Apprentissage et prévision de l'activité par [Régression logistique](http://wikistat.fr/pdf/st-m-app-rlogit.pdf)\n",
    "D'autres méthodes sont successivement testées dans les calepins complétant l'étude: SVM, analyse discriminate décisionnelle, $k$ plus proches voisins, forêts aléatoires, réseaux de neurones... Seule la régression logistique est utilisée dans ce calepin pour illustrer la phase d'apprentissage / modélisation pour la prévision du comportement.\n",
    "\n",
    "### 4.1 Principe\n",
    "Une méthode ancienne mais finalement efficace sur ces données. La régression logistique est adaptée à la prévision d'une variable binaire. Dans le cas multiclasse, la fonction logistique de la librairie `Scikit-learn` estime *par défaut* **un modèle par classe**: une classe contre les autres. \n",
    "\n",
    "La probabilité d'appartenance d'un individu à une classe est modélisée à l'aide d'une combinaison linéaire des variables explicatives. Pour transformer une combinaison linéaire à valeur dans $R$ en une probabilité à valeurs dans l'intervalle $[0, 1]$, une fonction de forme sigmoïdale, inverse de la fonction *logit*, est appliquée.  Ceci donne: $P(y_i=1)=\\frac{e^{Xb}}{1+e^{Xb}}$ ou encore, $\\log\\frac{P(y_i=1)}{1-P(y_i=1)}=Xb$\n",
    "\n",
    "\n",
    "### 4.2  Estimation du modèle sans optimisation\n",
    "Le modèle est estimé sans chercher à raffiner les valeurs de certains paramètres (pénalisation). Ce sera fait dans un deuxième temps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "ts = time.time()\n",
    "method = LogisticRegression()\n",
    "method.fit(Xtrain,ytrain)\n",
    "score = method.score(Xtest, ytest)\n",
    "ypred = method.predict(Xtest)\n",
    "te = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Prévision de l'activité de l'échantillon test\n",
    "Une fois le modèle estimé, l'erreur de prévision est évaluée, sans biais optimiste, sur un autre échantillon, dit échantillon test, qui n'a pas participé à l'apprentissage du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(\"Score : %f, time running : %d secondes\" %(score, te-ts))\n",
    "pd.DataFrame(confusion_matrix(ytest, ypred), index = labels, columns=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Quelles sont les classes qui restent difficiles à discriminer?\n",
    "\n",
    "**Q** Commenter la qualité des résultats obtenus. Sont-ils cohérents avec l'approche exploratoire.\n",
    "\n",
    "Un calepin suivant exploite d'autres méthodes d'apprentissage ainsi qu'une stratégie de hiérarchisation des modèles afin d'améliorer encore la prévision sur les données métiers. \n",
    "\n",
    "Un autre traite directement les signaux bruts en apprennant un réseau de neurones profond associant des couches convolutionnelles afin d'obtenir des résultats comparables sans prétraitement des données. Réseau intégrable à un équipement embarqué de faible consommation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {
    "height": "244px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
