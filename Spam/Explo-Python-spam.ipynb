{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<a href=\"http://www.insa-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo-insa.jpg\" style=\"float:left; max-width: 120px; display: inline\" alt=\"INSA\"/></a> \n",
    "\n",
    "<a href=\"http://wikistat.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/wikistat.jpg\" style=\"max-width: 250px; display: inline\"  alt=\"Wikistat\"/></a>\n",
    "\n",
    "<a href=\"http://www.math.univ-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo_imt.jpg\" style=\"float:right; max-width: 250px; display: inline\" alt=\"IMT\"/> </a>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Scénarios d'Exploration Statistique](https://github.com/wikistat/Exploration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration et caractérisation de pourriels avec <a href=\"https://www.python.org/\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/f/f8/Python_logo_and_wordmark.svg/390px-Python_logo_and_wordmark.svg.png\" style=\"max-width: 120px; display: inline\" alt=\"Python\"/></a>\n",
    "\n",
    "Réalisé par Claire Lambert et Marc le Chevoir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Résumé \n",
    "Exploration statistique  d'un ensemble de données textuelles afin de définir les caractéristiques des pourriels (spam). Cette analyse nécessite la mise en oeuvre successive et donc l'apprentissage approfondi des principales méthodes de statistique mutidimensionnelle: [ACP](http://wikistat.fr/pdf/st-m-explo-acp.pdf), [AFC](http://wikistat.fr/pdf/st-m-explo-afcm.pdf), [MDS](http://wikistat.fr/pdf/st-m-explo-mds.pdf), [classification](http://wikistat.fr/pdf/st-m-explo-classif.pdf) non supervisée. Le scénario d'analyse proposé vise à la représentation la plus explicite des données étudiées et teste également une approché spécifique pour la fouille de texte et les matrices très creuses, la factorisation d'une matrice non-négative ([NMF](http://wikistat.fr/pdf/st-m-explo-nmf.pdf)).\n",
    "\n",
    "\n",
    "## Introduction\n",
    "### Objectif\n",
    "Cette étude est un exemple d'*analyse textuelle* d'un corpus de documents, ici des courriels. Une telle analyse est classiquement basée sur la fréquence d'une sélection de mots. L'objectif est de mieux appréhender la structure particulière de ces données avant d'aborder un autre objectif de discrimination ou classification supervisée pour construire un *détecteur de pourriels* (*spams*)} personnalisé c'est-à-dire adapté au contenu spécifique de la boîte d'un internaute. Il s'agit en fait d'un modèle susceptible de prévoir la *qualité* d'un message reçu en fonction de son contenu. Le déroulement de cette étude est évidemment marqué par le type particulier des données mais celle-ci peut facilement se transposer à d'autres types de données textuelles  ou analyse du contenu: livres, pages web, discours politiques, réponses ouvertes dans des questionnaires... les exemples sont nombreux en sciences humaines, marketing lorsqu'il s'agit d'estimer des scores, par exemple, de satisfaction de clientèle. Les données se caractérisent généralement par des matrices très creuses c'est-à-dire comportant beaucoup de *0*s.\n",
    "\n",
    "### Données\n",
    "George, ingénieur chez HP dans le département *Computer Science* a recueilli un échantillon de messages électroniques dans chacun desquels il a évalué le nombre d'occurrences d'une sélection de mots et caractères. Les variables considérées sont, dans une première partie, des rapports: nombre d'occurrences d'un mot spécifique sur le nombre total de mots ou nombre d'occurrences d'un caractère sur le nombre de caractères du message avant d'être, dans une deuxième partie, des indicatrices ou facteurs: présence / absence de mots ou ensemble de caractères. Il a également considéré trois variables prenant en compte la casse (majuscule / minuscule) des caractères et une dernière qualitative binaire indiquant le classement qu'il a fait de chaque message : `spam` ou `Nsp`. Les variables d'occurrences sont décrites dans le tableau 1, celles associées à la casse dans le tableau 2. Ces données sont publiques, elles servent régulièrement de *benchmark* pour la comparaison de méthodes d'apprentissage machine:\n",
    "\n",
    "Frank A., Asuncion A. (2010). [UCI Machine Learning Repository](http://archive.ics.uci.edu/ml). Irvine, CA: University of California, School of Information and Computer Science.\n",
    "\n",
    "Ce sont donc finalement 58 variables qui sont observées sur 4601 messages dont 1813 pourriels (spams). La variable binaire `Spam` est présente à titre illustratif, elle est toujours considérée en supplémentaire dans ce travail exploratoire préliminaire. \n",
    "\n",
    "\n",
    "Le tableau ci-dessous liste 54 variables exprimant soit:\n",
    "- le rapport du nombre d'occurrence d'un mot (resp. de caractères) sur le nombre total de mots (de caractères) dans un message,\n",
    "- soit la présence ou non de ce mot (resp. caractère) dans le message, \n",
    "- des numéros (85...) qui sont ceux de bureau, téléphone, code postal de George.\n",
    "\n",
    "\n",
    "*Tableau 1:  Les colonnes contiennent successivement le libellé de la variable, le mot ou ensemble de caractères concernés, le libellé des modalités Présence / Absence utilisées après recodage.*\n",
    "\n",
    "Variable   | Mot ou Carac |    Modalités P/A   | Variable   | Mot ou Carac. |   Modalités  \n",
    "  --|-- --|-- --|-- --|-- --|--               \n",
    "make |    make |   make / Nmk|    X650 |   650 |   650 / N65 \n",
    "address |   address |   addr / Nad |   lab |   lab |   lab / Nlb\n",
    "all |   all |   all / Nal |   labs |   labs |   labs / Nls \n",
    "X3d |   3d |   3d / N3d |   telnet |   telnet |   teln / Ntl \n",
    "our |   our |   our / Nou |   X857 |   857 |   857 / N87 \n",
    "over |   over |   over / Nov |   data |   data |   data / Nda  \n",
    "remove |   remove |   remo / Nrm |   X415 |   415   | 415 / N41 \n",
    "internet |   internet |   inte / Nin |   X85 |   85 |   85 / N85 \n",
    "order |   order |   orde / Nor |   technology |   technology |   tech / Ntc \n",
    "mail |   mail |   mail / Nma |   X1999 |   1999 |   1999/ N19 \n",
    "receive |   receive |   rece / Nrc |   parts |   parts |   part / Npr \n",
    "will |   will |   will / Nwi |   pm |   pm |   pm / Npm \n",
    "people |   people |   peop / Npp |   direct |   direct |   dire / Ndr \n",
    "report |   report |   repo / Nrp |   cs |   cs |   cs / Ncs \n",
    "addresses |   addresses   | adds / Nas |   meeting |   meeting |   meet/Nmt \n",
    "free |   free |   free / Nfr |   original |   original |   orig / or \n",
    "business |   business |   busi / Nbs |   project |   project |   proj / Npj \n",
    "email |   email |   emai / Nem |   re |   re |   re / Nre \n",
    "you |   you |   you / Nyo |   edu |   edu |   edu / Ned \n",
    "credit |   credit |   cred / Ncr |   table    | table |   tabl / Ntb \n",
    "your |   your |   your / Nyr |   conference |   conferenc |e   conf / Ncf \n",
    "font |   order |   font / Nft |   CsemiCol |   ; |   Cscl / NCs \n",
    "X000 |   000 |   000 / N00 |   Cpar |   (    | Cpar / NCp \n",
    "money |   money |   mone/ Nmn |   Ccroch |   [    | Ccro / NCc \n",
    "hp |   hp |   hp / Nhp |   Cexclam |    ! |   Cexc / NCe \n",
    "hpl |   hpl |   hpl / Nhl |   Cdollar |   \\$ |   Cdol / NCd  \n",
    "george |   george |   geor / Nge |   Cdiese | # |   Cdie / NCi  \n",
    "\n",
    "\n",
    "\n",
    "Un deuxième tableau liste 4 variables dont celle dénombrant le nombre de lettres majuscules.\n",
    "\n",
    "\n",
    "*Tableau 2:Liste de 4 variables, de leur libellé et des modalités après recodage.*\n",
    "\n",
    "Code variable | Libellé | Modalités\n",
    "--|-- --|--\n",
    "Spam | Type de message pourriel ou non |  Spam / Nsp\n",
    "CapLM |\tNombre moyen de capitales par mot |  Mm1 / Mm2 / Mm3\n",
    "CapLsup\t| Nombre max de capitales par mot | Ms1 / Ms2 / Ms3 \n",
    "CapLtot\t| Nombre totale de lettres capitales |\tMt1 / Mt2 / Mt3 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préparation des données \n",
    "### Lecture\n",
    "Les données, déjà bien nettoyées et préparées à partir des messages bruts sont disponibles le fichier `spam.dat` chargé avec ce calepin dans le même répertoire .\n",
    " Les lire avec les commandes suivantes: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pylab as P\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listeVar=['spam','make','address','all','X3d','our','over','remove','internet','order','mail','receive','will',\n",
    "          'people','report','addresses','free','business','email','you','credit','your','font','X000','money','hp',\n",
    "          'hpl','george','X650','lab','labs','telnet','X857','data','X415','X85','technology','X1999','parts','pm',\n",
    "         'direct','cs','meeting','original','project','re','edu','table','conference','CsemiCol','Cpar','Ccroch','Cexclam',\n",
    "         'Cdollar','Cdiese','CapLM','CapLsup','CapLtot']\n",
    "\n",
    "spam=pd.read_csv(\"spam.dat\", sep = \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colonne_spam=spam['spam']\n",
    "spam=spam.drop('spam', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = spam.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "summary.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"dimension de la matrice : \",spam.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recherche du nombre de zeros dans la matrice spam afin de montrer qu'elle est très creuse.\n",
    "matrice_spam = np.matrix(spam)\n",
    "nb_zeros=0\n",
    "for i in range (0,matrice_spam.shape[0]):\n",
    "    for j in range (0,matrice_spam.shape[1]):\n",
    "        if matrice_spam[i,j]==0:\n",
    "            nb_zeros += 1\n",
    "print(\"nb_zeros = \" , nb_zeros)\n",
    "print(\"nb_element dans matrice = \", matrice_spam.shape[0]*matrice_spam.shape[1])\n",
    "print(\"difference = \",matrice_spam.shape[0]*matrice_spam.shape[1]-nb_zeros)\n",
    "print(\"ratio = \",float(nb_zeros)/(matrice_spam.shape[0]*matrice_spam.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description élémentaire\n",
    "**Q** Commenter les distributions des variables (symmétrie, nombre de \"0\"). Quelle est la principale caractéristique de la matrice étudiée? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1,3,1)\n",
    "spam.boxplot('all')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "spam['all'].hist()\n",
    "plt.xlabel(\"spam[ , all]\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1,3,1)\n",
    "spam.boxplot('CapLtot')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "spam['CapLtot'].hist()\n",
    "plt.xlabel(\"spam[ , CapLtot]\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam.boxplot(column=listeVar[1:55])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam.boxplot(column=listeVar[55:58])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Q** Commenter le choix de la transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lspam = np.log(1+spam)  #mise sous forme log des données\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "Lspam.boxplot('CapLtot')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "Lspam['CapLtot'].hist()\n",
    "plt.xlabel(\"spam[ , CapLtot]\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approche \"quantitative\"\n",
    "### [Analyse en composantes principales](http://wikistat.fr/pdf/st-m-explo-acp.pdf)\n",
    "Ce sont d'abord les variables quantitatives (nombres d'occurences) qui sont étudiées pour tenter de caractériser les spams. Ces variables sont toutes transformées selon les remarques de la première partie. \n",
    "\n",
    "Une première ACP est calculée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca.fit(Lspam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord1=pca.components_[0]*np.sqrt(pca.explained_variance_[0])\n",
    "coord2=pca.components_[1]*np.sqrt(pca.explained_variance_[1])\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "for i, j, nom in zip(coord1,coord2, Lspam.columns):\n",
    "    plt.text(i, j, nom)\n",
    "    plt.arrow(0,0,i,j,color='r')\n",
    "plt.axis((-0.5,2,-1,1))\n",
    "plt.title(\"Variables factor map (PCA)\")\n",
    "plt.xlabel(\"Dim 1\")\n",
    "plt.ylabel(\"Dim 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Que dire de cette représentation? Quel est le problème rencontré? Quelle est la matrice diagonalisée? Que serait-il préférable de faire?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En conséquence, une autre ACP est calculée fournissant un début de tableau ci-dessous. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lspamreduit= (Lspam-Lspam.mean())/Lspam.std()\n",
    "\n",
    "pca=PCA()\n",
    "c = pca.fit(Lspamreduit).transform(Lspamreduit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca.explained_variance_)\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Comment s'interprètent les *eigenvalues*? Quel choix de dimension ou nombre de composantes retenues, donnerait la règle dite de Kaiser? Cette règle est-elle raisonnablement applicable?\n",
    "\n",
    "**Q** Que sont les graphiques ci-dessous? Quel choix de dimension suggèrent-ils?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eboulis des valeurs propres\n",
    "plt.bar(range(len(pca.explained_variance_)),pca.explained_variance_)\n",
    "plt.title(\"Eigenvalues\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagrammes boîte des composantes principales\n",
    "plt.boxplot(c[:,0:5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Le graphique ci-dessous des variables est difficile à lire. Identifier néanmoins quelques variables permettant une première interprétation élémentaire des axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord1=pca.components_[0]*np.sqrt(pca.explained_variance_[0])\n",
    "coord2=pca.components_[1]*np.sqrt(pca.explained_variance_[1])\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "for i, j, nom in zip(coord1,coord2, Lspamreduit.columns):\n",
    "    plt.text(i, j, nom)\n",
    "    plt.arrow(0,0,i,j,color='r')\n",
    "plt.axis((-1.1,1.1,-1.1,1.1))\n",
    "# cercle\n",
    "cer=plt.Circle((0,0), radius=1, color='b', fill=False)\n",
    "ax.add_patch(cer)\n",
    "plt.title(\"Variables factor map (PCA)\")\n",
    "plt.xlabel(\"Dim 1\")\n",
    "plt.ylabel(\"Dim 2\")\n",
    "P.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Le graphique suivant représente les \"individus\"; les points rouges identifient les pourriels. Caractérisez sommairement les deux types de messages. A la vue de ce graphique, pensez vous facile de discriminer linéairement les deux groupes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "for i, j, nom, categorie in zip(c[:,0], c[:,1], Lspamreduit.index, colonne_spam):\n",
    "    color = \"red\" if categorie >= 1 else \"black\"\n",
    "    plt.text(i, j, nom, color=color)\n",
    "plt.axis((-6,30,-10,20)) \n",
    "plt.title(\"Individuals factor map (PCA)\")\n",
    "plt.xlabel(\"Dim 1\")\n",
    "plt.ylabel(\"Dim 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Q** Complétrer l'interprétation des axes et la caractérisation des variables vis-à-vis du type de message."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Classification des variables\n",
    "Ces résultat ne sont pas satisfaisants, notamment à cause du nombre de variables. Une classification de celles-ci pourrait aider à l'interprétation.\n",
    "#### [Classification ascendante hiérarchique](http://wikistat.fr/pdf/st-m-explo-classif.pdf)\n",
    "\n",
    "**Q** Quelles est, ci-dessous, la distance calculée entre les \"variables\"? Est-elle euclidienne? Quelle autre distance aurait pu être utilisée?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import *\n",
    "import scipy\n",
    "\n",
    "dist = scipy.spatial.distance.pdist(1-(Lspam.corr())**2)\n",
    "#On précise que dist est de type distance\n",
    "#pour pouvoir appliquer linkage ensuite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Comment choisir le nombre de classes? Jusifier.\n",
    "\n",
    "** Attention **: les résultats ne sont pas identiques à ceux de R car, dans Python, la distance \"ward\" ne correspond pas à la distance \"ward.D\" de R ; elle correspond à la distance \"ward.D2\" de R. Mais dans tous les cas, on observe le même genre de graphiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = linkage(dist, 'ward')\n",
    "plt.plot(maxdists(Z)[::-1][0:15], 'bo')\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Distances inter classes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Comment sont mesurées les distances entre sous-groupes de variables ? Retrouvez dans le dendrogramme les deux classes de variables les plus explicites pour caractériser les messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "plt.xlabel('Variable')\n",
    "plt.ylabel('Distance')\n",
    "dendrogram(Z,leaf_font_size=8.,labels=Lspam.columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Repésentation par positionnement multidimensionnel ([MDS](http://wikistat.fr/pdf/st-m-explo-mds.pdf))\n",
    "\n",
    "Représentation des classes dans le premier plan du MDS. \n",
    "\n",
    "**Q** La représentation obtenue ci-dessous est assez similaire à celle de l’ACP. Pourquoi selon-vous ?\n",
    "\n",
    "**Attention**, la fonction MDS de scikit-learn (`manifold`) est \"*non metric*\" et conduit à des résultats très différents; En revanche, à vérifier car ce n'est pas documenté, la fonction PCA  s'applique à une matrice de distances et conduit aux résultats du MDS !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrice de distances entre les varaibles 2 à 2\n",
    "dist2=np.sqrt(1-(Lspam.corr())**2)\n",
    "acpRed = PCA(n_components=2)\n",
    "ACPDataRed = acpRed.fit(dist2)\n",
    "# coordonnées des variables\n",
    "coord1=ACPDataRed.components_[0]*np.sqrt(ACPDataRed.explained_variance_[0])\n",
    "coord2=ACPDataRed.components_[1]*np.sqrt(ACPDataRed.explained_variance_[1])\n",
    "fig = plt.figure(figsize=(15,15))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "for i, j, nom in zip(coord1,coord2, listeVar[1:]):\n",
    "    plt.text(i, j, nom, fontsize=20)\n",
    "plt.axis((-0.175,0.06,-0.150,0.025))\n",
    "plt.title(\"MDS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Création des 4 classes en coupant le dendrogramme à la hauteur 2\n",
    "groupes = fcluster(Z,t=2,criterion='distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "coul=['g','r','b','k']\n",
    "for i, j, nom,indcoul in zip(coord1,coord2, Lspam.columns,groupes):\n",
    "    plt.text(i, j, nom,color=coul[indcoul-1])\n",
    "plt.axis((-0.175,0.06,-0.150,0.025))\n",
    "plt.title(\"CAH euclidien\")\n",
    "plt.xlabel(\"Dim 1\")\n",
    "plt.ylabel(\"Dim 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Retrouve-t-on des éléments d'interprétation des variables dans l'ACP?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Approche \"qualitative\" par Analyse des Correspondances Multiple ([AFCM](http://wikistat.fr/pdf/st-m-explo-afcm.pdf))\n",
    "Les distributions des variables les rendent peu adaptées à une ACP. La matrice des données est en fait très creuse (beaucoup de 0). Une autre piste est suivie en considérant les variables qualitatives : présence / absence, d’un mot ou caractère. \n",
    "### Recodage\n",
    "C'est souvent la partie la plus fastidieuse du travail: recoder en classe, c'est-à-dire transformer en facteur, chaque variable. Le point important est de donner à chaque modalité un identificateur suffisamment explicite pour que les sorties graphiques soient lisibles et ce d'autant plus qu'il y a de variables à traiter. \n",
    "\n",
    "Les commandes suivantes on été utilisées pour l'obtention du fichier `spamq.dat`. Elles sont données à titre d'exemple.\n",
    "\n",
    "Recodage en présence / absence des variables ou mots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "`spamq=data.frame(matrix(as.factor(as.matrix(spam[,2:55]>0)),ncol=54))`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les niveaux des facteurs sont renommés. Voici un exemple désignant la présente`make` et sont absence `Nmk` de la variable `make`.\n",
    "\n",
    "`make=factor(spamq[,\"make\"], c(TRUE, FALSE),labels=c(\"make\", \"Nmk\"))`\n",
    " \n",
    "Les variales dénombrant les lesttres majuscules sont traitées à part avec la commande suivante. \n",
    "\n",
    "**Q** Quelles sont les bornes des classes, que peut-on dire des effectifs de chacune d’elles ?\n",
    "\n",
    "``` \n",
    "CapLMq=cut(spam[,\"CapLM\"],breaks=quantile\n",
    "      (spam[,\"CapLM\"], probs = seq(0, 1, 1/3)), \n",
    "      labels = c(\"Mm1\",\"Mm2\",\"Mm3\"),\n",
    "      include.lowest = TRUE)\n",
    "```\n",
    "Enfin, toutes variables sont regroupées dans la même base et sauvegardées. \n",
    "\n",
    "Il suffit de relire le fichier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spam_quali=pd.read_csv(\"spamq.dat\", sep = \" \")\n",
    "spam_quali.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### [Analyse Factorielle des Correspondances Multiple](http://wikistat.fr/pdf/st-m-explo-afcm.pdf)\n",
    "Après le calcul de l'AFCM, une kyrielle de graphiques peuvent être construits. Certains sont proposés mais d'autres sont sans doute plus pertinents pour arriver à représenter au mieux la structure des données et expliquer les caractéristiques des spams.\n",
    "\n",
    "L’analyse factorielle des correspondances multiple exécutée dans R avec `FactoMineR` permet de considérer des variables comme supplémentaires. Ce n'est pas le cas de la fonction `MCA` écrite en python. Certaines variables prenant trop d'importance son supprimées de même que celle `spam`.\n",
    "\n",
    "Avant cela, il est nécessaire de remplacer chaque variable qualitative par son paquet d'indicatrices.\n",
    "\n",
    "**Q** Comment s'appelle la matrice ainsi obtenue.\n",
    "\n",
    "**Attention** Les commandes suivantes supposent que le package mca.py ait été installé ou chargé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import mca\n",
    "D=pd.DataFrame(pd.get_dummies(spam_quali))\n",
    "\n",
    "#on sauvegarde les catégories que l'on va enlever ensuite\n",
    "D_suplem = np.array([D['spamf_Nsp'],D['spamf_spam'],D['X857_857'],D['X857_N87'],D['X415_415'],D['X415_N41']]).T\n",
    "D_suplem_colonne = ['spamf_Nsp','X857_857','X415_415','spamf_spam','X857_N87','X415_N41']\n",
    "\n",
    "#on enlève les catégories\n",
    "D_drop=D.drop(['spamf_Nsp','X857_857','X415_415','spamf_spam','X857_N87','X415_N41'], axis=1)\n",
    "afc_drop = mca.MCA(D_drop,benzecri=False)\n",
    "\n",
    "afc_globale = mca.MCA(D,benzecri=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Valeurs singulières :\n",
    "print(afc_drop.L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Que sont les *eigenvalues* du tableau précédents? Comment s'interprètent ces valeurs ?\n",
    "\n",
    "\n",
    "**Q** Quelle AFC a été calculée ou quelle tableau a été décomposé (SVD) pour obtenir le graphe ci-dessous? Que dire de la représentation des individus de l’AFC par rapport à celle de l’ACP ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "for i, j, categorie in zip(afc_drop.fs_r()[:,0], -afc_drop.fs_r()[:,1], colonne_spam):\n",
    "    color = \"red\" if categorie >= 1 else \"black\"\n",
    "    plt.scatter(i,j,s=1,c=color)\n",
    "plt.axis((-0.7,1.5,-0.5,1.7))\n",
    "plt.xlabel(\"Dim 1\")\n",
    "plt.ylabel(\"Dim 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Comment le graphique de droite ci-dessous a-t-il été obtenu à partir de celui de gauche? En quoi celui-ci aide-t-il à caractériser un peu mieux les pourriels des autres messages ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "for i, j, nom in zip(afc_drop.fs_c()[:,0], -afc_drop.fs_c()[:,1], D_drop.columns):\n",
    "    plt.scatter(i,j,c='k',s=5)\n",
    "    plt.text(i,j,nom)\n",
    "        \n",
    "plt.axis((-2,2,-1,4))\n",
    "plt.title(\"MCA factor map\")\n",
    "plt.xlabel(\"Dim 1\")\n",
    "plt.ylabel(\"Dim 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zoom sur la partie centrale\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "for i, j, nom in zip(afc_drop.fs_c()[:,0], -afc_drop.fs_c()[:,1], D_drop.columns):\n",
    "    if (i>-1 and i<1 and j>-1 and j<1):\n",
    "        plt.scatter(i,j,c='k',s=5)\n",
    "        plt.text(i,j,nom)\n",
    "plt.axis((-1.2,1.2,-1.2,1.2))\n",
    "plt.title(\"MCA factor map\")\n",
    "plt.xlabel(\"Dim 1\")\n",
    "plt.ylabel(\"Dim 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** La dispersion des messages est plus encourageante qu'avec l'ACP mais que dire d'une possible discrimination linéaire entre pourriels et courriels?\n",
    "\n",
    "### Classification des modalités\n",
    "Comme les modalités sont très nombreuses, une classification de celles-ci va aider à l'interprétation.\n",
    "#### Par CAH puis [*k-means*](http://wikistat.fr/pdf/st-m-explo-classif.pdf)\n",
    "**Q** Quelle est la matrice qui est construite ci-dessous ? A partir de quelles \"composantes\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = linkage(afc_drop.fs_c()[:,:5], 'ward','euclidean')\n",
    "plt.plot(maxdists(Z)[::-1][0:15] , 'bo')\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Distance inter classes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "plt.xlabel('Variable')\n",
    "plt.ylabel('Distance')\n",
    "dendrogram(Z,leaf_font_size=8.,labels=D_drop.columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = fcluster(Z,t=5,criterion='distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 4\n",
    "freq_classes=np.zeros(n_classes)\n",
    "for i in range(0,np.size(classes)):\n",
    "    freq_classes[classes[i]-1]+=1\n",
    "print(freq_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import *\n",
    "\n",
    "kclasses = k_means(afc_drop.fs_c()[:,:5],4)[1]\n",
    "print(kclasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 4\n",
    "freq_kclasses=np.zeros(n_classes)\n",
    "for i in range(0,np.size(kclasses)):\n",
    "    freq_kclasses[kclasses[i]]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(freq_kclasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_croisee=pd.crosstab(classes,kclasses,rownames=[\"hclasmod\"],colnames=[\"kclasmod\"])\n",
    "print(table_croisee)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Q** Quel autre algorithme est utilisé ci-dessus? Que fournit-il comme résultat ? Que dire des deux classifications obtenues et donc de leur \"robustesse\"? \n",
    "\n",
    "#### Représentation des classes dans l'[AFCM](http://wikistat.fr/pdf/st-m-explo-afcm.pdf)\n",
    "\n",
    "**Q** Comment le graphe ci-dessous a-t-il été obtenu?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "coul=['b','k','r','g']\n",
    "for i, j, nom,indcoul in zip(afc_drop.fs_c()[:,0], -afc_drop.fs_c()[:,1], D_drop.columns,kclasses):\n",
    "    plt.scatter(i,j,c=coul[indcoul-1],s=5)\n",
    "    plt.text(i, j, nom,color=coul[indcoul-1])\n",
    "\n",
    "plt.axis((-1,2,-1,4))\n",
    "plt.title(\"MCA factor map\")\n",
    "plt.xlabel(\"Dim 1\")\n",
    "plt.ylabel(\"Dim 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "coul=['b','k','r','g']\n",
    "for i, j, nom,indcoul in zip(afc_drop.fs_c()[:,0], -afc_drop.fs_c()[:,1], D_drop.columns,classes):\n",
    "    plt.scatter(i,j,c=coul[indcoul-1],s=5)\n",
    "    plt.text(i, j, nom,color=coul[indcoul-1])\n",
    "\n",
    "plt.axis((-1,2,-1,4))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Lister les modalités des variables par classe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elem_dans_classe1=[]\n",
    "elem_dans_classe2=[]\n",
    "elem_dans_classe3=[]\n",
    "elem_dans_classe4=[]\n",
    "\n",
    "for nom, ind in  zip(D_drop.columns,classes):\n",
    "    if ind==1:\n",
    "        elem_dans_classe1.append(nom)\n",
    "    elif ind==2:\n",
    "        elem_dans_classe2.append(nom)\n",
    "    elif ind==3:\n",
    "        elem_dans_classe3.append(nom)\n",
    "    else:\n",
    "        elem_dans_classe4.append(nom)\n",
    "    \n",
    "print(elem_dans_classe1)\n",
    "print(elem_dans_classe2)\n",
    "print(elem_dans_classe3)\n",
    "print(elem_dans_classe4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Quelles co-occurrences de quels mots/caractères caractérisent principalement les spams? \n",
    "\n",
    "**Q** Quels sont les messages indifférentiables? Que suggérer à George pour améliorer son détecteur de pourriel? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approche par [Factorisation non négative](http://wikistat.fr/pdf/st-m-explo-nmf.pdf)\n",
    "Les données quantitatives sont reconsidérées mais en intégrant le caractère essentiellement non négatif de la matrice des données ainsi que sa parcinomie (matrice très creuse). Cette situation couramment répandue a suscité une nouvelle forme d'analyse dite *Non Negativ Matrix Factorization* ([NMF](http://wikistat.fr/pdf/st-m-explo-nmf.pdf)) dont le principe est de rechercher deux matrices de faible rang *r* de telle sorte que leur produit approche au mieux les valeurs observées. Cette méthode très utilisée pour la recommandation de produits par filtrage collaboratif est illustré sur ces données.\n",
    "\n",
    "**Q** Quelles différences majeurs entre une NMF et une SVD?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les matrices de faible rang ou les facteurs ne permettent plus de représentation comme en ACP mais au moins une classification non supervisée des objets lignes et colonnes de la matrice décomposée.\n",
    "\n",
    "Cette approche est testée sur les données de spam pour en comparer les résultats obtenus. \n",
    "\n",
    "### `NMF`\n",
    "La librairie `NMF` ([Gaujoux et Seoighe, 2010](https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-11-367)) de R propose plusieurs versions de l'algorithme de factorisation dont principalement *Multiplicative update algorithms* et *Alternate least Square* (ALS), adaptées à deux fonctions perte possibles: divergence de Kullback-Leibler (KL) ou moindres carrés. \n",
    "\n",
    "**Attention**, les choix: fonction objectif, algorithme, rang des matrices, influencent fortement les résultats obtenus qui se résument principalement à des classifications construites sur les facteurs de la décomposition. \n",
    "\n",
    "En Python, la fonction NMF de Scikit-learn présente bien moins d'options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Consulter la documentation, est-il possible d'identifier les algorithmes disponibles ainsi que la fonction objectif associée les pénalisations, les initialisation possibles?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les données quantitatives initiales (comptages \"non négatifs\") sont reprises en compte. \n",
    "\n",
    "**Attention**, les données sont bien creuses et non négatives, mais les variables s'expriment dans des unités et donc avec des variances très différentes. Une forme de normalisation est nécessaire. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "summary = spam.describe()\n",
    "summary.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NMF(n_components=2, init='random', random_state=0)\n",
    "W = model.fit_transform(spam)\n",
    "H = model.components_\n",
    "\n",
    "#Conversion du DataFrame en Matrice\n",
    "matrice_spam = np.matrix(spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "creux=np.zeros(np.shape(spam))\n",
    "print(np.shape(creux))\n",
    "\n",
    "part1=matrice_spam[:,0:54]\n",
    "part2=matrice_spam[:,54:57]\n",
    "creux[:,0:54]=np.log(1+part1)\n",
    "creux[:,54:57]=np.log(part2)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(creux)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Souci: quelques lignes (messages) se trouvent avec uniquement des 0; Celles-ci sont supprimées. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "creux_frame = pd.DataFrame(creux,columns=listeVar[1:])\n",
    "print(np.shape(creux_frame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compt=0\n",
    "for i in range(0,np.shape(creux)[0]):\n",
    "    if sum(creux[i,:])==0:\n",
    "        compt=compt+1\n",
    "        creux_frame=creux_frame.drop([i])\n",
    "print(compt , \"lignes vides supprimees\")\n",
    "print(np.shape(creux_frame)) #on a bien supprimé 3 lignes qui étaient vides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'algorithme snmf/l de R semble correspondre à l'algorithme Lsnmf du package nimfa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nimfa\n",
    "\n",
    "creux_matrice=np.matrix(creux_frame)\n",
    "lsnmf = nimfa.Lsnmf(creux_matrice, seed='random', rank=5, max_iter=2000)\n",
    "fit = lsnmf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il n'existe pas en python les même critères permettant d'optimiser certains choix dont le rang des matrices de la décomposition.\n",
    "\n",
    "Extraction des résulats numériques.\n",
    "\n",
    "Voici quelques caractéristiques de l'exécution de l'algorithme lsnmf mais bien plus pauvres que ce que produit le package NM fr R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the loss function according to Kullback-Leibler divergence. \n",
    "print (\"Distance Kullback-Leibler\", fit.distance(metric = \"kl\"))\n",
    "\n",
    "# Compute generic set of measures to evaluate the quality of the factorization\n",
    "sm = fit.summary()\n",
    "# Print sparseness (Hoyer, 2004) of basis and mixture matrix\n",
    "print (\"Sparseness W: %5.3f  H: %5.3f\" % (sm['sparseness'][0], sm['sparseness'][1]))\n",
    "# Print actual number of iterations performed\n",
    "print (\"Iterations\", sm['n_iter'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraction des matrices de la décompositon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W=fit.basis()\n",
    "H=fit.coef()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Production des graphiques (*heatmap*) associés aux matrices `w` et `h` de la factorisation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(W,center=0,cmap='RdBu',robust=True,xticklabels=True, yticklabels=True)\n",
    "plt.title('Basis components')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(H,center=0,cmap='RdBu',robust=True,xticklabels=listeVar[1:], yticklabels=True)\n",
    "plt.title('Mixture coefficients')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La packa `NMF` (Gaujoux et Seoighe, 2010) de R étant issu de la bioinformatique, la fontion *heatmap* représente la matrice des données initiales en permutant lignes et colonnes comme conséquence des classifications hiérarchiques. Le graphique peut être produit avec la fonction `clustermap` mais sans posisbilitée d'y adjoindre le caactère spam ou non des messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(creux_frame, center=0, cmap=\"RdBu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Quelle stratégie: ACP, AFCM ou NMF vous permet de mieux analyser les caractéristiques des pourriels?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
